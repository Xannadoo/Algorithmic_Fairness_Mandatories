{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithmic Fairness, Accountability, and Ethics, Spring 2024\n",
    "\n",
    "## Mandatory Assignment 1\n",
    "\n",
    "Please use the following code to prepare the dataset.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from folktables.acs import adult_filter\n",
    "from folktables import ACSDataSource\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "data_source = ACSDataSource(survey_year='2018', horizon='1-Year', survey='person')\n",
    "acs_data = data_source.get_data(states=[\"CA\"], download=True)\n",
    "\n",
    "feature_names = ['AGEP', # Age\n",
    "                 \"CIT\", # Citizenship status\n",
    "                 'COW', # Class of worker\n",
    "                 \"ENG\", # Ability to speak English\n",
    "                 'SCHL', # Educational attainment\n",
    "                 'MAR', # Marital status\n",
    "                 \"HINS1\", # Insurance through a current or former employer or union\n",
    "                 \"HINS2\", # Insurance purchased directly from an insurance company\n",
    "                 \"HINS4\", # Medicaid\n",
    "                 \"RAC1P\", # Recoded detailed race code\n",
    "                 'SEX']\n",
    "\n",
    "target_name = \"PINCP\" # Total person's income\n",
    "\n",
    "def data_processing(data, features, target_name:str, threshold: float = 35000):\n",
    "    df = data\n",
    "    ### Adult Filter (STARTS) (from Foltktables)\n",
    "    df = df[~df[\"SEX\"].isnull()]\n",
    "    df = df[~df[\"RAC1P\"].isnull()]\n",
    "    df = df[df['AGEP'] > 16]\n",
    "    df = df[df['PINCP'] > 100]\n",
    "    df = df[df['WKHP'] > 0]\n",
    "    df = df[df['PWGTP'] >= 1]\n",
    "    ### Adult Filter (ENDS)\n",
    "    ### Groups of interest\n",
    "    sex = df[\"SEX\"].values\n",
    "    ### Target\n",
    "    df[\"target\"] = df[target_name] > threshold\n",
    "    target = df[\"target\"].values\n",
    "    df = df[features + [\"target\", target_name]] ##we want to keep df before one_hot encoding to make Bias Analysis\n",
    "    df_processed = df[features].copy()\n",
    "    cols = [ \"HINS1\", \"HINS2\", \"HINS4\", \"CIT\", \"COW\", \"SCHL\", \"MAR\", \"SEX\", \"RAC1P\"]\n",
    "    df_processed = pd.get_dummies(df_processed, prefix=None, prefix_sep='_', dummy_na=False, columns=cols, drop_first=True)\n",
    "    df_processed = pd.get_dummies(df_processed, prefix=None, prefix_sep='_', dummy_na=True, columns=[\"ENG\"], drop_first=True)\n",
    "    return df_processed, df, target, sex\n",
    "\n",
    "data, data_original, target, group = data_processing(acs_data, feature_names, target_name)\n",
    "\n",
    "X_train, X_test, y_train, y_test, group_train, group_test = train_test_split(\n",
    "    data, target, group, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imports\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.compose import ColumnTransformer \n",
    "from sklearn.preprocessing import StandardScaler "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1 (Classifiers and fairness considerations)  \n",
    "1. Starting from the template, train two different classifiers on the training data: a white-box \n",
    "model using logistic regression, and a black-box model using a random forest. Consider \n",
    "feature engineering and scaling steps necessary for some of these classifiers and summarize \n",
    "the necessary changes in your report. For both models, report on the accuracy of the \n",
    "classifier on the test set.\n",
    "2. For each classifier, measure statistical parity, equalized odds (both in terms of  T = 0  and  T \n",
    "= 1 ), and equality of outcome (both in terms of  S = 0  and  S = 1 ) (Lecture 2). Plot the \n",
    "results and discuss the differences that you observe.  \n",
    "3. Change the classification pipeline to (approximately) fulfill one of the fairness criteria by post-\n",
    "processing the results. How did the intervention influence the different fairness criteria, how \n",
    "did it change the accuracy of the classification?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Constants\n",
    "\n",
    "seed = 23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7696317685840595"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_trans = ColumnTransformer(\n",
    "    [('scaler', StandardScaler(),['AGEP'])], \n",
    "    remainder='passthrough')\n",
    "\n",
    "column_trans.fit(X_train)\n",
    "\n",
    "\n",
    "X_train.AGEP = column_trans.transform(X_train)[:,0]\n",
    "\n",
    "X_test.AGEP = column_trans.transform(X_test)[:,0]\n",
    "\n",
    "\n",
    "LRclf = LogisticRegression(max_iter=5000, penalty='l2', C=0.98497534359086438, tol=1e-4, solver='saga', random_state=seed)\n",
    "LRclf.fit(X_train, y_train)\n",
    "LRclf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run this cell to use categorical features instead\n",
    "data_original.loc[data_original[data_original.ENG.isna()].index, 'ENG'] = -1\n",
    "X_train, X_test, y_train, y_test, group_train, group_test = train_test_split(\n",
    "    data_original[['AGEP', 'CIT', 'COW', 'SCHL', 'MAR', 'HINS1', 'HINS2', 'HINS4', 'RAC1P',\n",
    "       'ENG', 'SEX']], target, group, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.757851429739606"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RFclf = RandomForestClassifier(max_depth=2, random_state=seed, n_jobs=-1)\n",
    "RFclf.fit(X_train, y_train)\n",
    "RFclf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2 (Explaining white-box models)  \n",
    "1. Explain the trained logistic regression model. In particular, discuss which features in the \n",
    "model are deemed most relevant. Reflect on the interpretation. Does it fit your intuition \n",
    "about the prediction task?\n",
    "2. Pick one data point in the test dataset. Find a counterfactual data point that contrasts the \n",
    "outcome of the inference on this data point (e.g., \"had X had feature P >=, then it had been \n",
    "classified as ...\"). Describe how you used the model explanation to find such a counterfactual.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('SCHL_24.0', [2.4623154305875823, 11.731944618900648]),\n",
       " ('SCHL_23.0', [2.4337399113725606, 11.401442829379475]),\n",
       " ('SCHL_22.0', [2.2454122911649703, 9.444308558858031]),\n",
       " ('SCHL_21.0', [1.7451835119245798, 5.726952343041435]),\n",
       " ('SCHL_20.0', [0.9972422337533567, 2.7107957697281617]),\n",
       " ('HINS4_2', [0.8352327936304097, 2.305350656773828]),\n",
       " ('SCHL_19.0', [0.7108751261395431, 2.0357720366538357]),\n",
       " ('SCHL_18.0', [0.6628898640449583, 1.9403917080210855]),\n",
       " ('SCHL_17.0', [0.6210348419585144, 1.8608527342863883]),\n",
       " ('COW_5.0', [0.6084806863025892, 1.8376373292198678]),\n",
       " ('SCHL_3.0', [0.5713887140797329, 1.7707243746495454]),\n",
       " ('AGEP', [0.5571323241610381, 1.745659330573422]),\n",
       " ('SCHL_2.0', [0.46410058456358116, 1.590582950486057]),\n",
       " ('SCHL_16.0', [0.4485168544155348, 1.565987874269228]),\n",
       " ('COW_7.0', [0.2674562260973818, 1.306636432008279]),\n",
       " ('SCHL_12.0', [0.2512156255843019, 1.285587259951142]),\n",
       " ('SCHL_15.0', [0.2137259900227065, 1.2382833063224938]),\n",
       " ('SCHL_10.0', [0.18483949878242054, 1.2030253376000508]),\n",
       " ('SCHL_13.0', [0.12897196789107224, 1.1376582327592386]),\n",
       " ('SCHL_11.0', [0.11610822142173678, 1.123117410919573]),\n",
       " ('ENG_nan', [0.08983335517415851, 1.0939919604143005]),\n",
       " ('SCHL_7.0', [0.07546636449291619, 1.078386955015965]),\n",
       " ('COW_4.0', [0.07021277420165518, 1.0727364076057304]),\n",
       " ('CIT_4', [0.06752869172052324, 1.069860955309072]),\n",
       " ('SCHL_9.0', [0.05781267413539706, 1.0595165022745412]),\n",
       " ('COW_3.0', [0.04969377827721685, 1.0509492236145106]),\n",
       " ('MAR_3', [0.03308237824627733, 1.0336356848291912]),\n",
       " ('CIT_3', [0.006319942071353677, 1.0063399550433072]),\n",
       " ('COW_2.0', [-0.035882348673654474, 0.9647537913695552]),\n",
       " ('RAC1P_6', [-0.03636340368962533, 0.9642898033298747]),\n",
       " ('RAC1P_4', [-0.037766558076566585, 0.9629377046854609]),\n",
       " ('SCHL_6.0', [-0.039404606286822304, 0.9613616574747739]),\n",
       " ('RAC1P_8', [-0.051440735941548306, 0.9498599408492253]),\n",
       " ('RAC1P_7', [-0.05191240032108778, 0.9494120313893477]),\n",
       " ('SCHL_14.0', [-0.09602677190462518, 0.9084396950822736]),\n",
       " ('RAC1P_9', [-0.1046695757177086, 0.9006220608246929]),\n",
       " ('HINS2_2', [-0.11549378472971934, 0.8909261095664411]),\n",
       " ('CIT_2', [-0.11748096964740974, 0.889157432564893]),\n",
       " ('SCHL_8.0', [-0.14292969115213391, 0.8668150115178339]),\n",
       " ('SCHL_5.0', [-0.14547276275216364, 0.8646134394437748]),\n",
       " ('CIT_5', [-0.14961671111902455, 0.8610379394537289]),\n",
       " ('RAC1P_3', [-0.1722773434625974, 0.8417456881284499]),\n",
       " ('MAR_2', [-0.1988402655043444, 0.8196808141778109]),\n",
       " ('RAC1P_5', [-0.20595966691554346, 0.8138659013430835]),\n",
       " ('MAR_4', [-0.21396481523889835, 0.8073767918824757]),\n",
       " ('RAC1P_2', [-0.21773502072456433, 0.804338546476384]),\n",
       " ('ENG_2.0', [-0.29125378272701463, 0.7473259955209262]),\n",
       " ('SCHL_4.0', [-0.47571016099587665, 0.6214435747341073]),\n",
       " ('COW_6.0', [-0.621154970472265, 0.537323486312758]),\n",
       " ('ENG_3.0', [-0.6475035419652618, 0.5233506702631386]),\n",
       " ('MAR_5', [-0.7128035212027807, 0.4902677928204699]),\n",
       " ('SEX_2', [-0.8191408488301566, 0.440810214474038]),\n",
       " ('ENG_4.0', [-0.9818966429233139, 0.374599942329898]),\n",
       " ('HINS1_2', [-1.0169383982239666, 0.3617006300096514]),\n",
       " ('COW_8.0', [-1.219768947828528, 0.29529838837621986])]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = {}\n",
    "for i in range(len(LRclf.coef_[0])):\n",
    "    weights[LRclf.feature_names_in_[i]] = [LRclf.coef_[0][i]]\n",
    "\n",
    "for k,v in weights.items():\n",
    "    weights[k].append(np.exp(v)[0])\n",
    "\n",
    "sorted(weights.items(), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.331, 'AGEP'],\n",
       " [0.229, 'SCHL'],\n",
       " [0.168, 'HINS1'],\n",
       " [0.137, 'HINS4'],\n",
       " [0.079, 'MAR'],\n",
       " [0.028, 'ENG'],\n",
       " [0.014, 'CIT'],\n",
       " [0.006, 'SEX'],\n",
       " [0.006, 'RAC1P'],\n",
       " [0.002, 'COW'],\n",
       " [0.001, 'HINS2']]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF_imps = sorted([[round(i,3), j] for i, j in zip(RFclf.feature_importances_, RFclf.feature_names_in_)], reverse=True)\n",
    "\n",
    "RF_imps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3 (Model-agnostic explanations)  \n",
    "1. Both for the white-box and the black-box classifier, use the  shap  module to explain \n",
    "predictions. Contrast the two models to each other: What are similarities, how do they differ?\n",
    "2. For logistic regression, compare the model-agnostic explanation to your analysis in Task 2. \n",
    "How do the explanations differ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4 (Reflection)  \n",
    "Given the outcome of your study, which classifier is most suited for the prediction task under \n",
    "accuracy, explainability, and fairness considerations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
