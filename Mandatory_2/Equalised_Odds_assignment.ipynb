{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithmic Fairness, Accountability, and Ethics, Spring 2024\n",
    "\n",
    "## Mandatory Assignment 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from folktables.acs import adult_filter\n",
    "from folktables import ACSDataSource, BasicProblem, generate_categories\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "DOWNLOAD = False\n",
    "\n",
    "data_source = ACSDataSource(survey_year='2018', horizon='1-Year', survey='person')\n",
    "acs_data = data_source.get_data(states=[\"CA\"], download=DOWNLOAD)\n",
    "\n",
    "\n",
    "def adult_filter(data):\n",
    "    \"\"\"Mimic the filters in place for Adult data.\n",
    "    Adult documentation notes: Extraction was done by Barry Becker from\n",
    "    the 1994 Census database. A set of reasonably clean records was extracted\n",
    "    using the following conditions:\n",
    "    ((AAGE>16) && (AGI>100) && (AFNLWGT>1)&& (HRSWK>0))\n",
    "    \"\"\"\n",
    "    df = data\n",
    "    df = df[df['AGEP'] > 16]\n",
    "    df = df[df['PINCP'] > 100]\n",
    "    df = df[df['WKHP'] > 0]\n",
    "    df = df[df['PWGTP'] >= 1]\n",
    "    df = df[df[\"RAC1P\"] < 3] ## keep only Whites and African-Americans\n",
    "    return df\n",
    "\n",
    "\n",
    "ACSIncomeNew = BasicProblem(\n",
    "    features=[\n",
    "        'AGEP',\n",
    "        'COW',\n",
    "        'SCHL',\n",
    "        'MAR',\n",
    "        'RELP',\n",
    "        'WKHP',\n",
    "        'PWGTP',\n",
    "        'SEX',\n",
    "        'RAC1P',\n",
    "    ],\n",
    "    target='PINCP',\n",
    "    target_transform=lambda x: x > 25000,    \n",
    "    group=['SEX', 'RAC1P'],\n",
    "    preprocess=adult_filter,\n",
    "    postprocess=lambda x: np.nan_to_num(x, -1),\n",
    ")\n",
    "\n",
    "definition_df = data_source.get_definitions(download=DOWNLOAD)\n",
    "categories = generate_categories(features=ACSIncomeNew.features, definition_df=definition_df)\n",
    "features, labels, groups = ACSIncomeNew.df_to_pandas(acs_data, categories=categories, dummies=True)\n",
    "\n",
    "# Drop the \"redundant\" columns\n",
    "features = features.drop([\"RAC1P_White alone\", \n",
    "                          \"SEX_Male\", \n",
    "                          \"SCHL_1 or more years of college credit, no degree\",  \n",
    "                          \"MAR_Divorced\", \n",
    "                          \"RELP_Adopted son or daughter\",\n",
    "                          'COW_Working without pay in family business or farm' ], axis = 1) \n",
    "\n",
    "print(\"Columns with the protected features:\")\n",
    "for i, f in enumerate(features.columns):\n",
    "    if (\"RAC1P\" in f) or (\"SEX\" in f):\n",
    "        print(\"Column ID: %s\" %i, \"(%s)\"%f)\n",
    "        \n",
    "features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Task: \n",
    "Train three binary classifiers to predict income (label = True if income>$25k, otherwise label = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Train one classification model on the raw dataset and calculate its general \n",
    "accuracy, and respectively the accuracies for men and women and for \n",
    "different races. The model does not need to be fancy, logistic regression \n",
    "or Random Forest are completely fine choices. Remember to evaluate the \n",
    "model using cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imports\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, cross_validate\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import balanced_accuracy_score, f1_score, accuracy_score, make_scorer\n",
    "from sklearn.preprocessing import StandardScaler, FunctionTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import  pearsonr, spearmanr\n",
    "import scipy\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set constants\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "\n",
    "## This code is adapted from solution to data debias exercises\n",
    "X_train = features\n",
    "y_train = labels\n",
    "\n",
    "X_train = X_train.reset_index(drop=True)\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "\n",
    "# Subsample for efficiency\n",
    "## We considered stratifing here, as the data is unbalanced for white/african-american.\n",
    "\n",
    "N = 50000  # Subsample size\n",
    "\n",
    "# Generate random unique indices for subsampling\n",
    "indices_train = np.random.choice(X_train.shape[0], N, replace=False)\n",
    "\n",
    "# Subsample using the random indices\n",
    "### Train set\n",
    "X_train = X_train.iloc[indices_train]\n",
    "y_train = y_train.iloc[indices_train]\n",
    "\n",
    "# Print the counts\n",
    "print(f\"Number of Males in X_train: {np.sum(X_train['SEX_Female'] ==False)}\")\n",
    "print(f\"Number of Females in X_train: {np.sum(X_train['SEX_Female'] ==True)}\")\n",
    "print(f\"Number of Whites in X_train: {np.sum(X_train['RAC1P_Black or African American alone'] == False)}\")\n",
    "print(f\"Number of African Americans in X_train: {np.sum(X_train['RAC1P_Black or African American alone'] == True)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset for protected and non-protected features\n",
    "X_train_p = X_train.iloc[:, -2:]\n",
    "X_train_np = X_train.iloc[:, :-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Some helpful functions\n",
    "\n",
    "def cross_validator(X, y, n=5):\n",
    "    ''' Input:  X: training data\n",
    "                y: true labels\n",
    "                n: number of folds for cross validation, default=5\n",
    "        Output: 2 dataframes, with accuracy and f1 scores, \n",
    "                per fold for overall and the 4 groups:\n",
    "                male, female, white, african-american'''\n",
    "    scaler = StandardScaler() ## We need to scale within the cross val step to avoid data leakage\n",
    "    cls = LogisticRegression(penalty=None, max_iter=1000, random_state=seed)\n",
    "\n",
    "    kfold = KFold(n, shuffle=True, random_state=seed)\n",
    "    \n",
    "    X_np = X.iloc[:, :-2]\n",
    "    X_p = X.iloc[:, -2:]\n",
    "\n",
    "    accuracies = []\n",
    "    f1 = []\n",
    "    X = np.array(X_np).reshape(-1, 54)\n",
    "    X_p=np.array(X_p).reshape(-1, 2)\n",
    "    y = np.array(y).reshape(-1, 1)\n",
    "\n",
    "    for train_idx, test_idx in kfold.split(X):\n",
    "        pipe = make_pipeline(scaler, cls)\n",
    "        acc = []\n",
    "        f1s = []\n",
    "        X_train = X[train_idx]\n",
    "        y_train = y[train_idx]\n",
    "        X_test  = X[test_idx]\n",
    "        y_test  = y[test_idx]\n",
    "        X_p_test= X_p[test_idx]\n",
    "\n",
    "        pipe.fit(X_train, y_train.ravel())\n",
    "        y_hat = pipe.predict(X_test)\n",
    "\n",
    "        acc.append(accuracy_score(y_test, y_hat))\n",
    "        f1s.append(f1_score(y_test, y_hat))\n",
    "        for i in [0,1]:\n",
    "            for j in [0,1]:\n",
    "                acc.append(accuracy_score(y_test[X_p_test[:,i]==j], y_hat[X_p_test[:,i]==j]))\n",
    "                f1s.append(f1_score(y_test[X_p_test[:,i]==j], y_hat[X_p_test[:,i]==j]))\n",
    "        accuracies.append(acc)\n",
    "        f1.append(f1s)\n",
    "    return pd.DataFrame(accuracies, columns=['General','Male','Female','White','AA']),\\\n",
    "           pd.DataFrame(f1, columns=['General','Male','Female','White','AA'])\n",
    "\n",
    "def corr_mat(X):\n",
    "    '''The code is adapted from solution to data debias exercises\n",
    "    Takes a dataframe and computes the pearsons correlations, and their \n",
    "    statistical significance between all features,\n",
    "    returning 2 arrays: correlations, and p_values'''\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "\n",
    "    # Compute correlation matrix\n",
    "    n_features = X.shape[1]\n",
    "\n",
    "    corr_ = np.zeros((n_features, n_features))\n",
    "    p_ = np.zeros((n_features, n_features))\n",
    "\n",
    "    for i in range(n_features):\n",
    "        for j in range(n_features):\n",
    "            corr_[i,j], p_[i,j] = pearsonr(X[:,i], X[:,j])\n",
    "            corr_ = np.nan_to_num(corr_, 0)\n",
    "            # Handle NaN values in correlation coefficient by setting p-value to 1\n",
    "            if np.isnan(corr_[i,j]):\n",
    "                p_[i,j] = 1\n",
    "\n",
    "    return corr_, p_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs, f1s = cross_validator(X_train, y_train)\n",
    "\n",
    "pd.DataFrame([accs.mean(), f1s.mean()], index=['Accuracy', 'F1']).T.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2\n",
    "\n",
    "2. Using the “fairer” (reprojected) versions of the dataset, build two classification models (see more below) and calculate: \n",
    "+ a) their overall accuracy, \n",
    "+ b) their accuracies split for men and women, and \n",
    "+ c) their accuracies split for different races. Subtasks: \n",
    " \n",
    "- Build one classification model trained on data reprojected using the \n",
    "de-correlation method from the paper “A Geometric Solution to Fair \n",
    "Representations”. Record your results and create a plot of how \n",
    "accuracies vary as functions of 𝜆Î[0,1].  \n",
    " \n",
    "- Build one classification model using reprojected data from FairPCA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2.1: A Geometric Solution to Fair Representations\n",
    "### Correlations in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr, p = corr_mat(X_train)\n",
    "\n",
    "alpha = 0.05 # Significance level\n",
    "corrected_alpha = alpha / (X_train.shape[1]**2/2) #bonferronni correction,\n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "sns.heatmap(corr, cmap=\"coolwarm\", xticklabels=features.columns, yticklabels=features.columns,\n",
    "            square=True, vmin=-1, vmax=1, mask= p > corrected_alpha)\n",
    "\n",
    "plt.title(f\"Pearson's Correlation Coeff between all features (filtered by p > {alpha})\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Visualise columns of the correlation matrix that are associated only with protected features (see Lecture Slides)\n",
    "plt.figure(figsize=(2,9))\n",
    "sns.heatmap(corr[:, -2:], cmap=\"coolwarm\", xticklabels=features.columns[-2:], yticklabels=features.columns,  \n",
    "            mask = p[:, -2:]  > corrected_alpha, vmin=-1, vmax=1, square=True)\n",
    "plt.title(\"Pearson's Correlation Coeff between SEX and other variables (Masked by p value)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1.2 Simple Logistic Regression \n",
    "\n",
    "### Use a Geometric solution to debias data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#More helpful functions\n",
    "\n",
    "def debias_features(X, l=0):\n",
    "    '''based on exercises. Debias using de-correllation'''\n",
    "     \n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X)\n",
    "    X = scaler.transform(X)\n",
    "\n",
    "    #FunctionTransfomer makes it an array and I want it to be a dataFrame\n",
    "    X = pd.DataFrame(X)\n",
    "    \n",
    "    #seperate protected attributes\n",
    "    X_p = X.iloc[:, -2:]\n",
    "    X_np = X.iloc[:, :-2]\n",
    "\n",
    "    # Find the basis from the protected attributes\n",
    "    orthbasis = scipy.linalg.orth(X_p)\n",
    "    \n",
    "    # Debias nonprotected features by projecting them onto the basis\n",
    "    X_np_debiased = X_np - orthbasis @ orthbasis.T @ X_np\n",
    "\n",
    "    # Return debiased nonprotected features, tempered by lambda: r′_j(λ) = r_j + λ⋅ (x_j− r_j)\n",
    "    return X_np_debiased + l * (X_np - X_np_debiased)\n",
    "\n",
    "\n",
    "def cross_validator_debiased(X, y, n=5, l=0):\n",
    "    ''' Input:  X: training data\n",
    "                y: true labels\n",
    "                n: number of folds for cross validation, default=5\n",
    "                l: lambda value to pass to the debiaser\n",
    "        Output: 2 dataframes, with accuracy and f1 scores, \n",
    "                per fold for overall and the 4 groups:\n",
    "                male, female, white, african-american\n",
    "                \n",
    "        note: scaling is moved to the debias_features function'''\n",
    "    \n",
    "    transformer = FunctionTransformer(debias_features, kw_args={'l': l}) #Debias as part of the pipeline to avoid leakage\n",
    "    cls = LogisticRegression(penalty=None, max_iter=1000, random_state=seed)\n",
    "  \n",
    "    kfold = KFold(n, shuffle=True, random_state=seed)\n",
    "    \n",
    "    X_np = X.iloc[:, :-2]\n",
    "    X_p = X.iloc[:, -2:]\n",
    "\n",
    "    accuracies = []\n",
    "    f1 = []\n",
    "    pos_rates = []\n",
    "\n",
    "    for train_idx, test_idx in kfold.split(X):\n",
    "\n",
    "        pipe = make_pipeline(transformer, cls)\n",
    "        acc = []\n",
    "        f1s = []\n",
    "        pr = []\n",
    "        X_train = X_np.iloc[train_idx]\n",
    "        y_train = y.iloc[train_idx]\n",
    "        X_test  = X_np.iloc[test_idx]\n",
    "        y_test  = y.iloc[test_idx]\n",
    "        X_p_test= X_p.iloc[test_idx]\n",
    "\n",
    "        pipe.fit(X_train, y_train)\n",
    "        y_hat = pipe.predict(X_test)\n",
    "\n",
    "        acc.append(accuracy_score(y_test, y_hat))\n",
    "        f1s.append(f1_score(y_test, y_hat))\n",
    "        pr.append(np.mean(y_hat))\n",
    "\n",
    "        for i in [0,1]:\n",
    "            for j in [0,1]:\n",
    "                acc.append(accuracy_score(y_test[X_p_test.iloc[:,i]==j], y_hat[X_p_test.iloc[:,i]==j]))\n",
    "                f1s.append(f1_score(y_test[X_p_test.iloc[:,i]==j], y_hat[X_p_test.iloc[:,i]==j]))\n",
    "                pr.append(np.mean(y_hat[X_p_test.iloc[:,i]==j]))\n",
    "        accuracies.append(acc)\n",
    "        f1.append(f1s)\n",
    "        pos_rates.append(pr)\n",
    "\n",
    "    return pd.DataFrame(accuracies, columns=['General','Male','Female','White','AA']),\\\n",
    "           pd.DataFrame(f1, columns=['General','Male','Female','White','AA']),\\\n",
    "           pd.DataFrame(pos_rates, columns=['General','Male','Female','White','AA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Lambda = 0, so max decorrelating\n",
    "\n",
    "X_train_np_debiased = debias_features(X_train.astype('float'))\n",
    "X_train_debiased = np.concatenate([X_train_np_debiased, X_train.iloc[:, -2:]], axis=1)\n",
    "\n",
    "corr2, p2 = corr_mat(X_train_debiased)\n",
    "\n",
    "# Plot correlations with protected features\n",
    "plt.figure(figsize=(2,9))\n",
    "sns.heatmap(corr2[:, -2:], cmap=\"coolwarm\", xticklabels=features.columns[-2:], yticklabels=features.columns,\n",
    "            mask = p2[:, -2:]  > corrected_alpha, vmin=-1, vmax=1, square=True)\n",
    "plt.title(\"Pearson's Correlation Coeff between SEX and other variables (Masked by p value)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_values = np.linspace(0, 1, 11)  # 11 values from 0 to 1\n",
    "accuracies = pd.DataFrame(columns=['General','Male','Female','White','AA'])\n",
    "f1_scores = pd.DataFrame(columns=['General','Male','Female','White','AA'])\n",
    "positive_rates = pd.DataFrame(columns=['General','Male','Female','White','AA'])\n",
    "\n",
    "y_hat_preds = []\n",
    "\n",
    "for l in lambda_values:\n",
    "\n",
    "    #usinng cross validation\n",
    "    acs, fs, pos = cross_validator_debiased(X_train, y_train, n=5, l=l)\n",
    "    accuracies = pd.concat([accuracies, pd.DataFrame(acs.mean()).T])\n",
    "    f1_scores = pd.concat([f1_scores, pd.DataFrame(fs.mean()).T])\n",
    "    positive_rates = pd.concat([positive_rates, pd.DataFrame(pos.mean()).T])\n",
    "\n",
    "\n",
    "accuracies.index = lambda_values\n",
    "f1_scores.index = lambda_values\n",
    "positive_rates.index = lambda_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross validation scores\n",
    "\n",
    "_, ax = plt.subplots(3,1, figsize=(5, 10), sharex=True)\n",
    "titles = ['Accuracies', 'F1 scores', 'Positive rates']\n",
    "lines = ['solid', '--', (5, (10, 3)), (0, (3, 2, 1, 2, 1, 2)),'dashdot']\n",
    "\n",
    "\n",
    "for i, df in enumerate([accuracies, f1_scores, positive_rates]):\n",
    "    for j in range(5):\n",
    "        ax[i].plot(df.iloc[:,j], linestyle=lines[j], label=df.columns[j])\n",
    "        ax[i].set_title(f'{titles[i]}')\n",
    "\n",
    "ax[1].legend(bbox_to_anchor=(1,1))\n",
    "\n",
    "plt.xticks(lambda_values, labels=[round(x,1) for x in lambda_values])\n",
    "plt.xlabel('lambda value')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2.2: Fair PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a class for Fair PCA\n",
    "class FairPCA:\n",
    "    def __init__(self, Xs, p_idxs, n_components):\n",
    "        self.fit(Xs, p_idxs, n_components)\n",
    "\n",
    "    def fit(self, Xs, p_idxs, n_components):\n",
    "        # Extract protected features\n",
    "        Xs_p = Xs.iloc[:, p_idxs]\n",
    "\n",
    "        # Compute projection matrix (U)\n",
    "        # Set z\n",
    "        Z = Xs_p\n",
    "\n",
    "        # Compute orthonormal null-space spanned by Z.T @ Xs\n",
    "        Z = Z - Z.mean(0) #center\n",
    "        R = scipy.linalg.null_space(Z.T @ Xs)\n",
    "\n",
    "        # Compute orthonormal eigenvectors (L)\n",
    "        eig_vals, L = scipy.linalg.eig(R.T @ Xs.T @ Xs @ R)\n",
    "\n",
    "        # U = R * Eigenvectors\n",
    "        self.U = R @ L[:, :n_components]\n",
    "\n",
    "    def project(self, Xs):\n",
    "        # Project data into fair space using projection matrix U\n",
    "        return Xs @ self.U\n",
    "    \n",
    "\n",
    "class NormalPCA:\n",
    "    def __init__(self, n_components):\n",
    "        self.n_components = n_components\n",
    "        self.pca = PCA(n_components=n_components, random_state=seed)\n",
    "\n",
    "    def fit(self, X):\n",
    "        self.pca.fit(X)\n",
    "\n",
    "    def project(self, X):\n",
    "        return self.pca.transform(X)\n",
    "    \n",
    "\n",
    "def debias_features_adjust_fairness_level(X_fair, X_pca, l=0):\n",
    "    # r′j(λ) = rj + λ⋅ (xj− rj)\n",
    "    return X_fair + l * (X_pca - X_fair)\n",
    "\n",
    "def cross_validator_debiased_pca(X, y, n=5, l=0):\n",
    "    ''' Input:  X: training data\n",
    "                y: true labels\n",
    "                n: number of folds for cross validation, default=5\n",
    "                l: lambda value to pass to the debiaser\n",
    "        Output: 2 dataframes, with accuracy and f1 scores, \n",
    "                per fold for overall and the 4 groups:\n",
    "                male, female, white, african-american\n",
    "                '''\n",
    "    cls = LogisticRegression(penalty=None, max_iter=1000, random_state=seed)\n",
    "  \n",
    "    kfold = KFold(n, shuffle=True, random_state=seed)\n",
    "    \n",
    "    X_p = X.iloc[:, -2:]\n",
    "\n",
    "    accuracies = []\n",
    "    f1 = []\n",
    "    pos_rates = []\n",
    "\n",
    "    for train_idx, test_idx in kfold.split(X):\n",
    "        acc = []\n",
    "        f1s = []\n",
    "        pr = []\n",
    "\n",
    "        X_train = X.iloc[train_idx]\n",
    "        y_train = y.iloc[train_idx]\n",
    "        X_test  = X.iloc[test_idx]\n",
    "        y_test  = y.iloc[test_idx]\n",
    "        X_p_test= X_p.iloc[test_idx]\n",
    "\n",
    "        fair = FairPCA(X_train, [54, 55], 30)\n",
    "        norm = NormalPCA(30)\n",
    "        norm.fit(X_train)\n",
    "\n",
    "        X_train_debiased = fair.project(X_train)\n",
    "        X_test_debiased = fair.project(X_test)\n",
    "        X_train_pca = norm.project(X_train)\n",
    "        X_test_pca = norm.project(X_test)\n",
    "\n",
    "        X_train_final = debias_features_adjust_fairness_level(X_train_debiased, X_train_pca, l=l)\n",
    "        X_test_final = debias_features_adjust_fairness_level(X_test_debiased, X_test_pca, l=l)\n",
    "\n",
    "\n",
    "        cls.fit(X_train_final, y_train)\n",
    "        y_hat = cls.predict(X_test_final)\n",
    "\n",
    "        acc.append(accuracy_score(y_test, y_hat))\n",
    "        f1s.append(f1_score(y_test, y_hat))\n",
    "        pr.append(np.mean(y_hat))\n",
    "\n",
    "        for i in [0,1]:\n",
    "            for j in [0,1]:\n",
    "                acc.append(accuracy_score(y_test[X_p_test.iloc[:,i]==j], y_hat[X_p_test.iloc[:,i]==j]))\n",
    "                f1s.append(f1_score(y_test[X_p_test.iloc[:,i]==j], y_hat[X_p_test.iloc[:,i]==j]))\n",
    "                pr.append(np.mean(y_hat[X_p_test.iloc[:,i]==j]))\n",
    "        accuracies.append(acc)\n",
    "        f1.append(f1s)\n",
    "        pos_rates.append(pr)\n",
    "\n",
    "    return pd.DataFrame(accuracies, columns=['General','Male','Female','White','AA']),\\\n",
    "           pd.DataFrame(f1, columns=['General','Male','Female','White','AA']),\\\n",
    "           pd.DataFrame(pos_rates, columns=['General','Male','Female','White','AA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "protected_features = [54, 55]\n",
    "n_components = 30\n",
    "fair_pca = FairPCA(X_train.astype('float'), p_idxs=protected_features, n_components=n_components)\n",
    "\n",
    "# Project training and test data into fair space\n",
    "X_train_debiased = fair_pca.project(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_debiased_p = np.concatenate([X_train_debiased, X_train_p], axis=1)\n",
    "\n",
    "corr, p = corr_mat(X_train_debiased_p)\n",
    "\n",
    "\n",
    "# Plot correlations with protected features\n",
    "plt.figure(figsize=(2,9))\n",
    "sns.heatmap(corr[:, -2:], cmap=\"coolwarm\", xticklabels=features.columns[-2:],\n",
    "            mask = p[:, -2:]  > corrected_alpha, vmin=-1, vmax=1, square=True)\n",
    "plt.title(\"Pearson's Correlation Coeff between SEX and other variables (Masked by p value)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_values = np.linspace(0, 1, 11)  # 11 values from 0 to 1\n",
    "accuracies = pd.DataFrame(columns=['General','Male','Female','White','AA'])\n",
    "f1_scores = pd.DataFrame(columns=['General','Male','Female','White','AA'])\n",
    "positive_rates = pd.DataFrame(columns=['General','Male','Female','White','AA'])\n",
    "\n",
    "y_hat_preds = []\n",
    "\n",
    "for l in lambda_values:\n",
    "\n",
    "    #usinng cross validation\n",
    "    acs, fs, pos = cross_validator_debiased_pca(X_train.astype('float'), y_train, n=5, l=l)\n",
    "    accuracies = pd.concat([accuracies, pd.DataFrame(acs.mean()).T])\n",
    "    f1_scores = pd.concat([f1_scores, pd.DataFrame(fs.mean()).T])\n",
    "    positive_rates = pd.concat([positive_rates, pd.DataFrame(pos.mean()).T])\n",
    "\n",
    "\n",
    "accuracies.index = lambda_values\n",
    "f1_scores.index = lambda_values\n",
    "positive_rates.index = lambda_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross validation scores\n",
    "\n",
    "_, ax = plt.subplots(3,1, figsize=(5, 10), sharex=True)\n",
    "titles = ['Accuracies', 'F1 scores', 'Positive rates']\n",
    "lines = ['solid', '--', (5, (10, 3)), (0, (3, 2, 1, 2, 1, 2)),'dashdot']\n",
    "\n",
    "\n",
    "for i, df in enumerate([accuracies, f1_scores, positive_rates]):\n",
    "    for j in range(5):\n",
    "        ax[i].plot(df.iloc[:,j], linestyle=lines[j], label=df.columns[j])\n",
    "        ax[i].set_title(f'{titles[i]}')\n",
    "\n",
    "ax[1].legend(bbox_to_anchor=(1,1))\n",
    "\n",
    "plt.xticks(lambda_values, labels=[round(x,1) for x in lambda_values])\n",
    "plt.xlabel('lambda value')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "man_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
